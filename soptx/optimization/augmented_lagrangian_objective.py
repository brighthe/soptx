from typing import Optional, Literal, Union, Dict, TYPE_CHECKING
from fealpy.backend import backend_manager as bm
from fealpy.typing import TensorLike
from fealpy.functionspace import Function

from soptx.optimization.volume_objective import VolumeObjective
from soptx.optimization.vanish_stress_constraint import VanishingStressConstraint
from soptx.optimization.apparent_stress_constaint import ApparentStressConstraint 
from soptx.utils.base_logged import BaseLogged
from soptx.utils import timer

# ä½¿ç”¨ TYPE_CHECKING é¿å…å¾ªç¯å¯¼å…¥ï¼Œä»…ç”¨äºç±»å‹æç¤º
if TYPE_CHECKING:
    from soptx.optimization.al_mma_optimizer import ALMMMAOptions

class AugmentedLagrangianObjective(BaseLogged):
    def __init__(self,
                volume_objective: VolumeObjective, 
                stress_constraint: Union[VanishingStressConstraint, ApparentStressConstraint],
                options: 'ALMMMAOptions',
                initial_lambda: Optional[TensorLike] = None,
                diff_mode: Literal["auto", "manual"] = "manual",
                enable_logging: bool = True,
                logger_name: Optional[str] = None
            ) -> None:
        """å¢å¹¿æ‹‰æ ¼æœ—æ—¥ç›®æ ‡å‡½æ•° - ä½“ç§¯æœ€å°åŒ– + åº”åŠ›çº¦æŸ

        å½’ä¸€åŒ–å¢å¹¿æ‹‰æ ¼æœ—æ—¥å­é—®é¢˜:
            J^(k)(z, U) = f(z) + (1/N) Â· P^(k)(z, U)

        å…¶ä¸­:
        - f(z) ä¸ºä½“ç§¯ç›®æ ‡å‡½æ•° (å½’ä¸€åŒ–), ç”± VolumeObjective è®¡ç®—
        - P^(k) ä¸ºç½šå‡½æ•°é¡¹:
            P^(k) = Î£_j [Î»_j Â· h_j + (Î¼/2) Â· h_jÂ²]
        - h_j = max(g_j, -Î»_j/Î¼), Eq. (40)
        - g_j ä¸ºåº”åŠ›çº¦æŸ
        """
        super().__init__(enable_logging=enable_logging, logger_name=logger_name)

        self._volume_objective = volume_objective
        self._stress_constraint = stress_constraint

        self._is_apparent = isinstance(stress_constraint, ApparentStressConstraint)

        self._options = options

        self._diff_mode = diff_mode

        # ç¼“å­˜: ç”¨äºåœ¨ fun() å’Œ jac() ä¹‹é—´å…±äº«ä¸­é—´ç»“æœ
        self._cache_g = None  # çº¦æŸå€¼ g, shape (NC, NQ)
        self._cache_h = None  # è¾…åŠ©ç­‰å¼çº¦æŸ h, shape (NC, NQ)

        self._analyzer = stress_constraint.analyzer
        self._disp_mesh = self._analyzer.disp_mesh
        self._NC = self._disp_mesh.number_of_cells()
        
        self._interpolation_scheme = self._analyzer.interpolation_scheme
        self._material = self._analyzer.material

        self._n_sub = self._interpolation_scheme.n_sub if self._interpolation_scheme.n_sub is not None else 1
        self._is_multiresolution = (self._n_sub > 1)

        # --- ALM å‚æ•°åˆå§‹åŒ– ---
        
        # ç½šå› å­ Î¼^(k)
        self.mu = float(options.mu_0)
        # æœ€å¤§ç½šå› å­ Î¼_max
        self.mu_max = float(options.mu_max)

        # æ‹‰æ ¼æœ—æ—¥ä¹˜å­ lambda çš„åˆå§‹åŒ–
        if initial_lambda is not None:
            # Case A: çƒ­å¯åŠ¨
            if self._is_multiresolution:
                expected_shape = (self._NC, self._n_sub, 1)
            else:
                expected_shape = (self._NC, 1)

            if initial_lambda.shape != expected_shape:
                self._log_error(
                    f"Shape mismatch: æœŸæœ› {expected_shape}, å®é™…å¾—åˆ° {initial_lambda.shape}"
                )
            self.lamb = bm.copy(initial_lambda)
        else:
            # Case B: å†·å¯åŠ¨
            init_val = options.lambda_0_init_val
            if self._is_multiresolution:
                self.lamb = bm.full((self._NC, self._n_sub, 1), init_val, dtype=bm.float64)
            else:
                self.lamb = bm.full((self._NC, 1), init_val, dtype=bm.float64)

    def fun(self, 
            density: Union[Function, TensorLike],
            state: Optional[Dict] = None, 
            **kwargs
        ) -> float:
        # 1. è®¡ç®—ä½“ç§¯éƒ¨åˆ† f
        f = self._volume_objective.fun(density, state)

        # 2. è®¡ç®—åº”åŠ›çº¦æŸ g
        g = self._stress_constraint.fun(density, state) # å•åˆ†è¾¨ç‡: (NC, NQ) | å¤šåˆ†è¾¨ç‡: (NC, n_sub, NQ)

        # è®¾è®¡çº¦å®šæ–­è¨€ï¼šæ¯å•å…ƒæ°å¥½1ä¸ªåº”åŠ›è¯„ä¼°ç‚¹
        assert g.shape[-1] == 1, (
                        f"è¦æ±‚ NQ=1ï¼Œä½†å®é™… NQ={g.shape[-1]}ï¼Œè¯·æ£€æŸ¥ç§¯åˆ†é˜¶æ•°è®¾ç½®ã€‚"
                    )

        # 3. è®¡ç®— ALM çš„ h å’Œ Penal
        #    h_j = max(g_j, -lambda_j / mu)
        h = bm.maximum(g, -self.lamb / self.mu) # å•åˆ†è¾¨ç‡: (NC, NQ) | å¤šåˆ†è¾¨ç‡: (NC, n_sub, NQ)

        penal = bm.sum(self.lamb * h + 0.5 * self.mu * h**2)

        self._cache_g = g
        self._cache_h = h

        # 4. ç»„è£…å½’ä¸€åŒ–åçš„å¢å¹¿æ‹‰æ ¼æœ—æ—¥ç›®æ ‡å‡½æ•° J
        n_constraints = g.numel() if hasattr(g, 'numel') else g.size
        J = f + penal / n_constraints

        return J
    
    def jac(self, 
            density: Union[Function, TensorLike], 
            state: Optional[dict] = None,
            diff_mode: Optional[Literal["auto", "manual"]] = None,
            **kwargs
        ) -> TensorLike:
        mode = diff_mode if diff_mode is not None else self._diff_mode

        if mode == "manual":
            return self._manual_differentiation(density=density, state=state, **kwargs)
        
        elif mode == "auto":  
            return self._auto_differentiation(density=density, state=state, **kwargs)
        
        else:
            error_msg = f"Unknown diff_mode: {diff_mode}"
            self._log_error(error_msg)

    def _manual_differentiation(self, 
                    density: Union[Function, TensorLike],
                    state: Optional[dict] = None, 
                    enable_timing: bool = None, 
                    **kwargs
                ) -> TensorLike:
        t = None
        if enable_timing:
            t = timer(f"ç›®æ ‡å‡½æ•°çµæ•åº¦åˆ†æ")
            next(t)

        if state is None:
            state = {}
        
        # --- ç¡®ä¿æ­£å‘è®¡ç®—å·²å®Œæˆï¼Œç¼“å­˜ gã€h åŠ state ä¸­é—´é‡ ---
        if self._is_apparent:
            if self._cache_g is None or 'stiffness_ratio' not in state:
                self.fun(density, state)
        else:
            if self._cache_g is None or 'stiffness_ratio' not in state \
                    or 'stress_deviation' not in state:
                self.fun(density, state)

        # ------------------------------------------------------------------ #
        # ç¬¬ä¸€æ­¥ï¼šå‡†å¤‡å…¬å…±ä¸­é—´é‡
        # ------------------------------------------------------------------ #
        slim = self._stress_constraint._stress_limit
        g    = self._cache_g   # (NC, NQ) æˆ– (NC, n_sub, NQ)
        h    = self._cache_h   # (NC, NQ) æˆ– (NC, n_sub, NQ)

        # æ¿€æ´»é›†ï¼šå½“ g > -Î»/Î¼ æ—¶çº¦æŸæ¿€æ´»ï¼Œh = gï¼›å¦åˆ™ h = -Î»/Î¼ï¼Œæ¢¯åº¦ä¸ºé›¶
        mask = g > (-self.lamb / self.mu)  # ä¸ gã€h åŒå½¢

        # ------------------------------------------------------------------ #
        # ç¬¬äºŒæ­¥ï¼šè®¡ç®— dP/d(Ïƒ^vM)ï¼Œç”¨äºæ„é€ ä¼´éšè½½è·
        #   ä½ç§»å…ƒ: âˆ‚g/âˆ‚Ïƒ^vM = m_E Â· (3Î›Â² + 1) / Ïƒ_lim
        #   æ··åˆå…ƒ: âˆ‚g/âˆ‚Ïƒ^vM = 1 / Ïƒ_lim
        # ------------------------------------------------------------------ #
        if self._is_apparent:
            dhdVM_val = bm.ones_like(g) / slim
        else:
            s = state['stress_deviation']
            m_E = state['stiffness_ratio']
            if self._is_multiresolution:
                dhdVM_val = m_E[:, :, None] * (3 * s**2 + 1) / slim
            else:
                dhdVM_val = m_E[:, None] * (3 * s**2 + 1) / slim

        dPenaldVM = (self.lamb + self.mu * h) * bm.where(mask, dhdVM_val, 0.0)

        if enable_timing:
            t.send('ç½šå‡½æ•°åå¯¼æ•°')

        # ------------------------------------------------------------------ #
        # ç¬¬ä¸‰æ­¥ï¼šè®¡ç®—æ˜¾å¼åå¯¼æ•° âˆ‚P/âˆ‚m_E|_explicit
        #   ä½ç§»å…ƒ: âˆ‚g/âˆ‚m_E = Î›Â³ + Î›
        #   æ··åˆå…ƒ: âˆ‚g/âˆ‚m_E = -(1 - Îµ)
        # ------------------------------------------------------------------ #
        dgdm_E = self._stress_constraint.compute_partial_gradient_wrt_mE(state=state)
        dPenaldm_E_explicit = bm.where(mask, (self.lamb + self.mu * h) * dgdm_E, 0.0)  # (NC, NQ) æˆ– (NC, n_sub, NQ)

        # ------------------------------------------------------------------ #
        # ç¬¬å››æ­¥ï¼šä¼´éšæ³•æ±‚è§£éšå¼åå¯¼æ•° âˆ‚P/âˆ‚m_E|_implicit
        #
        #   ç»„è£…ä¼´éšè½½è·: F_adj = âˆ‚P/âˆ‚(çŠ¶æ€å˜é‡)
        #     ä½ç§»å…ƒä½œç”¨åœ¨ä½ç§»è‡ªç”±åº¦: F_adj = (âˆ‚Ïƒ^v/âˆ‚U)^T Â· dP/dÏƒ^v
        #     æ··åˆå…ƒä½œç”¨åœ¨åº”åŠ›è‡ªç”±åº¦: F_adj = (âˆ‚Ïƒ^v/âˆ‚Î£)^T Â· dP/dÏƒ^v
        #
        #   æ±‚è§£ä¼´éšæ–¹ç¨‹:
        #     ä½ç§»å…ƒ: K Â· Ïˆ = F_adj
        #     æ··åˆå…ƒ: [A  B^T; B  0] Â· [Î»_Ïƒ; Î»_u] = [F_adj; 0]  (å¤ç”¨æ­£å‘ LU åˆ†è§£)
        #
        #   éšå¼é¡¹:
        #     ä½ç§»å…ƒ: Ïˆ^T Â· (âˆ‚K_e/âˆ‚m_E) Â· U_e
        #     æ··åˆå…ƒ: (1/m_EÂ²) Â· Î»_Ïƒ,e^T Â· Aâ°_e Â· Î£_e
        # ------------------------------------------------------------------ #
        adjoint_load = self._stress_constraint.compute_adjoint_load(dPenaldVM=dPenaldVM, state=state)  # (gdofs, )

        if enable_timing:
            t.send('ç»„è£…ä¼´éšå‘é‡')

        adjoint_vector = self._analyzer.solve_adjoint(rhs=adjoint_load, rho_val=density)  # (gdofs, )

        if enable_timing:
            t.send('è§£ä¼´éšæ–¹ç¨‹')

        dPenaldm_E_implicit = self._stress_constraint.compute_implicit_sensitivity_term(
                                                        adjoint_vector, state)  # (NC,) æˆ– (NC, n_sub)
        
        # ------------------------------------------------------------------ #
        # ç¬¬äº”æ­¥ï¼šé“¾å¼æ³•åˆ™ç»„è£… dP/dÏ
        # ------------------------------------------------------------------ #
        # æ˜¾å¼é¡¹å¯¹ NQ ç»´åº¦æ±‚å’Œï¼Œè¿˜åŸä¸ºå•å…ƒçº§æ ‡é‡
        dPenaldm_E_explicit_reduced = bm.sum(dPenaldm_E_explicit, axis=-1)  # (NC,) æˆ– (NC, n_sub)

        # è®¡ç®— dm_E/dÏ = (dE/dÏ) / Eâ‚€
        dm_E_drho = self._interpolation_scheme.interpolate_material_derivative(
                                                            material=self._material, rho_val=density
                                                        ) / self._material.youngs_modulus  # (NC,) æˆ– (NC, n_sub)

        if self._is_apparent:
            # æ··åˆå…ƒ:
            #   æ˜¾å¼é¡¹: (âˆ‚P/âˆ‚m_E|_explicit) Â· dm_E/dÏ
            #   éšå¼é¡¹: (1/m_EÂ²) Â· Î»_Ïƒ^T Aâ° Î£ Â· m_E' = dPenaldm_E_implicit Â· dm_E_drho
            #           (compute_implicit_sensitivity_term å·²é¢„é™¤ m_EÂ²ï¼Œå¤–éƒ¨åªéœ€ä¹˜ m_E')
            dP_drho = dPenaldm_E_explicit_reduced * dm_E_drho + dPenaldm_E_implicit * dm_E_drho           # (NC,)
        else:
            # ä½ç§»å…ƒ: æ˜¾å¼ä¸éšå¼é€šè¿‡åŒä¸€ dm_E/dÏ ä¸²è”
            dP_drho = (dPenaldm_E_explicit_reduced + dPenaldm_E_implicit) * dm_E_drho  # (NC,) æˆ– (NC, n_sub)
            
        # ------------------------------------------------------------------ #
        # ç¬¬å…­æ­¥ï¼šå½’ä¸€åŒ–å¹¶ç»„è£…æ€»æ¢¯åº¦
        #   dJ/dÏ = âˆ‚f/âˆ‚Ï + (1/N) Â· dP/dÏ
        # ------------------------------------------------------------------ #
        dVol_drho     = self._volume_objective.jac(density=density, state=state)
        n_constraints = g.numel() if hasattr(g, 'numel') else g.size
        dP_drho_norm = dP_drho / n_constraints

        # current_step = kwargs.get('iteration', 0) 
        # if current_step <= 1: 
        #     self._check_gradient_magnitude_balance(dVol_drho, dP_drho_norm, current_step)

        dJ_drho = dVol_drho + dP_drho_norm  # (NC,) æˆ– (NC, n_sub)

        if enable_timing:
            t.send('å…¶ä»–')
            t.send(None)

        return dJ_drho

    def _check_gradient_magnitude_balance(self, 
                                          dVol_drho: TensorLike, 
                                          dP_drho_norm: TensorLike, 
                                          step_k: int = 0) -> None:
        """
        éªŒè¯ä½“ç§¯æ¢¯åº¦ä¸æƒ©ç½šé¡¹æ¢¯åº¦æ˜¯å¦åœ¨åŒä¸€æ•°é‡çº§ï¼Œè¾…åŠ©æ ¡å‡† mu_0
        """
        # è®¡ç®—æœ€å¤§ç»å¯¹å€¼ (æ— ç©·å¤§èŒƒæ•°)
        max_vol_grad = bm.max(bm.abs(dVol_drho))
        max_pen_grad = bm.max(bm.abs(dP_drho_norm))
        
        # è®¡ç®—æ¯”å€¼ (åŠ å…¥æå°æ•°é¿å…é™¤é›¶æŠ¥é”™)
        ratio = max_pen_grad / (max_vol_grad + 1e-12)
        
        print(f"\n[{'æ··åˆå…ƒ' if self._is_apparent else 'ä½ç§»å…ƒ'}] --- ALM è¿­ä»£æ­¥ {step_k} æ¢¯åº¦é‡çº§è¯Šæ–­ ---")
        print(f"æœ€å¤§ä½“ç§¯æ¢¯åº¦ ||dVol_drho||_inf   : {max_vol_grad:.4e}")
        print(f"æœ€å¤§æƒ©ç½šæ¢¯åº¦ ||dP_drho_norm||_inf: {max_pen_grad:.4e}")
        print(f"æ¢¯åº¦é‡çº§æ¯”å€¼ (Penal / Vol)       : {ratio:.4f}")
        
        # ç»™å‡ºå­¦æœ¯å»ºè®®
        if ratio < 0.1:
            print("ğŸ‘‰ è¯Šæ–­ç»“è®ºï¼šæƒ©ç½šåŠ›ã€è¿‡å¼±ã€‘ã€‚ä¼˜åŒ–å™¨å¯èƒ½ä¼šæ— è§†åº”åŠ›çº¦æŸç–¯ç‹‚æŒ–æ´ã€‚")
            print("ğŸ’¡ è°ƒæ•´å»ºè®®ï¼šè¯·æˆå€ã€å¢å¤§ã€‘åˆå§‹æƒ©ç½šå› å­ mu_0ã€‚")
        elif ratio > 10.0:
            print("ğŸ‘‰ è¯Šæ–­ç»“è®ºï¼šæƒ©ç½šåŠ›ã€è¿‡å¼ºã€‘ã€‚åº”åŠ›æƒ©ç½šé¡¹å°†ä¸»å¯¼ä¼˜åŒ–ï¼Œå¯èƒ½å¯¼è‡´æ‹“æ‰‘æ¼”åŒ–åœæ»æˆ–å…¨ç°ã€‚")
            print("ğŸ’¡ è°ƒæ•´å»ºè®®ï¼šè¯·æˆå€æˆ–æŒ‰æ•°é‡çº§ã€å‡å°ã€‘åˆå§‹æƒ©ç½šå› å­ mu_0ã€‚")
        else:
            print("ğŸ‘‰ è¯Šæ–­ç»“è®ºï¼šé‡çº§ã€å®Œç¾å¹³è¡¡ã€‘ï¼(ç†æƒ³èŒƒå›´ 0.1 ~ 10.0)")
            print("ğŸ’¡ è°ƒæ•´å»ºè®®ï¼šä¿æŒå½“å‰ mu_0 ä¸å˜ã€‚")
        print("-" * 50 + "\n")

    # def _manual_differentiation_backup(self, 
    #                     density: Union[Function, TensorLike],
    #                     state: Optional[dict] = None, 
    #                     enable_timing: bool = False, 
    #                     **kwargs
    #                 ) -> TensorLike:
    #     # --- ç¼“å­˜æ£€æŸ¥ä¸çŠ¶æ€åŒæ­¥ ---
    #     if (self._cache_g is None) or ('stiffness_ratio' not in state) or ('stress_deviation' not in state):
    #         self.fun(density, state)
        
    #     # --- è·å–ç¼“å­˜çš„ç‰©ç†é‡ ---
    #     slim = self._stress_constraint._stress_limit
    #     E = state['stiffness_ratio']  # å•åˆ†è¾¨ç‡: (NC,)         | å¤šåˆ†è¾¨ç‡: (NC, n_sub)
    #     s = state['stress_deviation'] # å•åˆ†è¾¨ç‡: (NC, NQ)      | å¤šåˆ†è¾¨ç‡: (NC, n_sub, NQ)

    #     g = self._cache_g             # å•åˆ†è¾¨ç‡: (NC, NQ)      | å¤šåˆ†è¾¨ç‡: (NC, n_sub, NQ)
    #     h = self._cache_h             # å•åˆ†è¾¨ç‡: (NC, NQ)      | å¤šåˆ†è¾¨ç‡: (NC, n_sub, NQ)

    #     # --- ç¡®å®šæ¿€æ´»é›† a1 (Mask) ---
    #     #  é€»è¾‘: å½“ g > -lambda/mu æ—¶ï¼Œh = g, æ­¤æ—¶çº¦æŸæ¿€æ´»ï¼ˆæˆ–è¿åï¼‰
    #     limit_term = -self.lamb / self.mu
    #     mask = g > limit_term         # å•åˆ†è¾¨ç‡: (NC, NQ)      | å¤šåˆ†è¾¨ç‡: (NC, n_sub, NQ)

    #     # --- è®¡ç®—æ˜¾å¼çµæ•åº¦ ---
    #     #  è®¡ç®— dPenaldVM (ç½šå‡½æ•°å¯¹ Von Mises åº”åŠ›çš„åå¯¼æ•°)
    #     #  å•åˆ†è¾¨ç‡: (NC, NQ)      | å¤šåˆ†è¾¨ç‡: (NC, n_sub, NQ)
    #     if self._is_multiresolution:
    #         dhdVM_val = E[:, :, None] * (3 * s**2 + 1) / slim  # (NC, n_sub, NQ)
    #     else:
    #         dhdVM_val = E[:, None] * (3 * s**2 + 1) / slim     # (NC, NQ)
    #     # dhdVM_val = E[:, None] * (3 * s**2 + 1) / slim
    #     dhdVM = bm.where(mask, dhdVM_val, 0.0)
    #     dPenaldVM = (self.lamb + self.mu * h) * dhdVM  

    #     #  è®¡ç®— dPenal/dE çš„æ˜¾å¼éƒ¨åˆ†
    #     #  å•åˆ†è¾¨ç‡: (NC, NQ) | å¤šåˆ†è¾¨ç‡: (NC, n_sub, NQ)
    #     dgdE = self._stress_constraint.compute_partial_gradient_wrt_mE(state=state)
    #     dPenaldE_explicit = bm.where(mask, (self.lamb + self.mu * h) * dgdE, 0.0) 

    #     # --- ä¼´éšæ³• ---        
    #     #  è®¡ç®—ä¼´éšè½½è· F_adj = - (dVM/dU)^T * dPenaldVM
    #     adjoint_load = self._stress_constraint.compute_adjoint_load(dPenaldVM=dPenaldVM, state=state) # (gdofs, )
        
    #     # è§£ä¼´éšæ–¹ç¨‹: K * psi = F_adj
    #     adjoint_vector = self._analyzer.solve_adjoint(rhs=adjoint_load, rho_val=density) # (gdofs, )
        
    #     # --- è®¡ç®—éšå¼çµæ•åº¦ ---
    #     # dPenal/dE_implicit = psi^T * (dF_int / dE)
    #     dPenaldE_implicit = self._stress_constraint.compute_implicit_sensitivity_term(adjoint_vector, state)  # (NC, )

    #     # --- æ˜¾å¼é¡¹å½’çº¦: å¯¹ NQ ç»´åº¦æ±‚å’Œ (NQ å§‹ç»ˆåœ¨æœ€åä¸€ç»´) ---
    #     dPenaldE_explicit_reduced = bm.sum(dPenaldE_explicit, axis=-1) # å•åˆ†è¾¨ç‡: (NC,) | å¤šåˆ†è¾¨ç‡: (NC, n_sub)

    #     # --- æ€»çµæ•åº¦ (å…³äºåˆšåº¦å˜é‡ E) ---
    #     if self._is_multiresolution:
    #         dPenaldE_total = dPenaldE_explicit_reduced + dPenaldE_implicit[:, None]  # (NC, n_sub)
    #     else:
    #         dPenaldE_total = dPenaldE_explicit_reduced + dPenaldE_implicit  # (NC,)
    #     # dPenaldE_total = dPenaldE_explicit_reduced + dPenaldE_implicit # å•åˆ†è¾¨ç‡: (NC,) | å¤šåˆ†è¾¨ç‡: (NC, n_sub)

    #     # --- é“¾å¼æ³•åˆ™: dPenal/drho = dPenal/dE * dE/drho ---
    #     # è·å– dE/drho (å–å†³äºå…·ä½“çš„æ’å€¼æ¨¡å‹)
    #     dE_drho_absolute = self._interpolation_scheme.interpolate_material_derivative(
    #                                                 material=self._material, 
    #                                                 rho_val=density
    #                                             )  # å•åˆ†è¾¨ç‡: (NC, ) | å¤šåˆ†è¾¨ç‡: (NC*n_sub, )
    #     E0 = self._material.youngs_modulus
    #     dE_drho = dE_drho_absolute / E0    # å•åˆ†è¾¨ç‡: (NC, ) | å¤šåˆ†è¾¨ç‡: (NC*n_sub, )

    #     dP_drho = dPenaldE_total * dE_drho # å•åˆ†è¾¨ç‡: (NC, ) | å¤šåˆ†è¾¨ç‡: (NC*n_sub, )

    #     # è®¡ç®—ä¸»ç›®æ ‡å‡½æ•° (ä½“ç§¯) çš„æ¢¯åº¦
    #     dVol_drho = self._volume_objective.jac(density=density, state=state) # å•åˆ†è¾¨ç‡: (NC, ) | å¤šåˆ†è¾¨ç‡: (NC*n_sub, )

    #     # å½’ä¸€åŒ–å¤„ç†
    #     dP_drho_normalized = dP_drho / self._NC  # å•åˆ†è¾¨ç‡: (NC, ) | å¤šåˆ†è¾¨ç‡: (NC*n_sub, )

    #     # ç»„è£…æ€»æ‹‰æ ¼æœ—æ—¥å‡½æ•°çš„æ¢¯åº¦ (å…³äºç‰©ç†å¯†åº¦ rho)
    #     dJ_drho = dVol_drho + dP_drho_normalized # å•åˆ†è¾¨ç‡: (NC, ) | å¤šåˆ†è¾¨ç‡: (NC*n_sub, )

    #     return dJ_drho
    
    def update_multipliers(self) -> None:
        """æ›´æ–°æ‹‰æ ¼æœ—æ—¥ä¹˜å­ Î» å’Œ ç½šå› å­ Î¼.
        
        æ­¤æ–¹æ³•åº”åœ¨æ¯ä¸€è½® ALM å¤–å±‚è¿­ä»£ç»“æŸæ—¶è°ƒç”¨.
        """
        if self._cache_h is None:
            raise RuntimeError(
                "update_multipliers() å¿…é¡»åœ¨ fun() ä¹‹åè°ƒç”¨, "
                "ä»¥ç¡®ä¿ h å·²è¢«è®¡ç®—å¹¶ç¼“å­˜."
            )
    
        # 1. æ›´æ–°æ‹‰æ ¼æœ—æ—¥ä¹˜å­ Î»
        # Î»^(k+1) = Î»^(k) + Î¼^(k) Â· h
        self.lamb = self.lamb + self.mu * self._cache_h
        
        # 2. æ›´æ–°ç½šå› å­ Î¼
        # Î¼^(k+1) = min(Î± Â· Î¼^(k), Î¼_max) [cite: 303]
        self.mu = min(self._options.alpha * self.mu, self.mu_max)
    